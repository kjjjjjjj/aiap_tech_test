{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<img src='aisg_logo.png' width=\"700px\">  \n",
    "<br>\n",
    "# AI Apprentice Programme\n",
    "## Take-home Written Assignment\n",
    "\n",
    "### Problem 5 - Machine Learning\n",
    "__This problem is compulsory for all candidates.__\n",
    "\n",
    "The core of artificial intelligence problems today are machine learning algorithms - they have brought new heights to the capabilities of AI. Although AI engineering goes way beyond model building, having modelling and data analytical knowledge is core for any AI engineer today.\n",
    "\n",
    "Hence, this problem will test your ability to build a basic model based on a given dataset. This will be an open-ended problem, and your goal is to build a model to predict a given Y, then provide justification for model evaluation and report your results. Your end goal is 1) a model, and 2) a write up of approximately 2 pages on your modelling process.\n",
    "\n",
    "You will be assessed on your ability to build a performant model through a scientific process, but also on your ability to write clean, reproducible code. While you may use any library, you should display your ability to handle any model you use - that is, your ability to tune the model and work beyond a simple API call.\n",
    "\n",
    "You are open to use all kinds of models in this exercise - __we are not looking only for the most cutting edge model__, but also your ability to work with data, and conduct model tuning and selection. While accuracy is important, we will also favour a well-justified and fitted linear regression model over a blind call of a black box API if you do not display mastery over the black box model you are using.\n",
    "\n",
    "You should be able to complete this question in 2-3 hours. However, you are not restricted to this time frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "In many organisations with data-heavy operations or machine learning products, there exists a need for a lot of compute power. Compute power is distributed to scientists in two main ways - through scaling out and scaling up. Scaling out involves virtualising and instantiating computers that run computation jobs separately, while scaling up involves building up a large computer with massive computational power that runs computation jobs sequentially. This is known as High Performance Computing (HPC).\n",
    "\n",
    "Our problem involves the operation of a HPC. While a naive way to manage jobs within the HPC computer would be through a first-in, first-out (FIFO) queue, this might not be optimal. In some scenarios, a job that takes just a few minutes might end up waiting for previous jobs that take days to finish before it can start. Instead, HPC computers typically have a job scheduler that manages the jobs, giving priority to those that are deemed to be more important, or deemed to be completed more quickly.\n",
    "\n",
    "To help the job scheduler understand which jobs to prioritise, we have a machine learning problem to predict the time it will take for the job submitted to finish. Given a list of parameters (explained below), we predict how long it takes for the job to finish. To simplify the problem, the duration has been reduced from a continuous duration (regression problem) into categories (classification problem). We have the categories of 0: less than 1min, 1: 1-10mins, 2: 10mins-1hr or 3: \\>1hr. Build a model to predict the `duration` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "|column|description|\n",
    "|-|-|\n",
    "|`Unnamed: 0`|index column|\n",
    "|`type`|types of model categories, labels removed|\n",
    "|`time`|time as percentage of day that passed, i.e. 0.5 = 12 noon|\n",
    "|`dayofweek`| day of week, 1 = monday, 7 = sunday |\n",
    "|`models`|number of models executed by script|\n",
    "|`params`|number of parameters to run in script|\n",
    "|`queuelen`|number of jobs in queue to at time where job was initialised|\n",
    "|`trials`|number of trials ran by model for model testing |\n",
    "|`duration`| categorical duration of model, as specified above|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "You may find the dataset stored as a text file in `data_ml.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pandas.read_csv('data_ml.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverables\n",
    "#### 1. Code\n",
    "Please give us the script or notebook you use to model. We allow both R and Python. Do check with us if you wish to other other languages. Please also ensure that your file runs, as we may run it to test that your model truly produces the results you promise. Lastly, please ensure your code is of quality.\n",
    "\n",
    "#### 2. Report\n",
    "Please submit a report with writing of not more than 2 pages in length (this is only writing - we allow it to stretch if you have ample visualisations). However, please be concise in your report. You are expected to include:\n",
    "- Exploratory Data Analysis\n",
    "- Feature engineering (you are allowed to drop or include additional data columns)\n",
    "- Model selection and tuning\n",
    "- Model interpretation\n",
    "- Metrics for model evaluation (please at least provide a confusion matrix - you can go beyond a confusion matrix).\n",
    "\n",
    "These deliverables can be submitted as a notebook, or as a script + a PDF report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code of Honour\n",
    "By completing this assignment and submitting your response, you automatically declare that your work is your own without plagiarisation. Should we find that you have copied your solution, your response will be heavily penalised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This is the final assignment. Thank you for your hard work, and for applying to the AI Apprentice Programme! :)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL NAME: TAM HOU HENG\n",
    "# GITHUB USERNAME: noelcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\default.LAPTOP-2CI68M4P\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# Normalisation (0 to +1) (MinMaxScaler)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.layers import Flatten, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Did nothing to the dataset, just to have an idea, to see where are we now from good prediction. Use this as baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_baseline = pd.read_csv('data_ml.csv')\n",
    "df_baseline.drop(columns='Unnamed: 0' , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>time</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>models</th>\n",
       "      <th>params</th>\n",
       "      <th>queuelen</th>\n",
       "      <th>trials</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.568056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>11252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.715972</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.222917</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.424306</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4023.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type      time  dayofweek  models   params  queuelen  trials  duration\n",
       "0  13.0  0.568056        2.0   148.0  11252.0       0.0    40.0       2.0\n",
       "1  12.0  0.715972        2.0     7.0   5923.0       0.0    40.0       1.0\n",
       "2  13.0  0.222917        5.0    62.0   1906.0       1.0    20.0       0.0\n",
       "3   5.0  0.424306        5.0     8.0   4023.0      30.0    40.0       0.0\n",
       "4  12.0  0.672222        5.0     1.0   2480.0       0.0    40.0       1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type         0\n",
       "time         0\n",
       "dayofweek    0\n",
       "models       0\n",
       "params       0\n",
       "queuelen     0\n",
       "trials       0\n",
       "duration     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline.fillna(df_baseline.mean(), inplace = True)\n",
    "df_baseline.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_baseline.drop(\"duration\", axis=1).values\n",
    "y = df_baseline['duration'].values\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.78      0.78       689\n",
      "          1       1.00      0.01      0.01       370\n",
      "          2       0.00      0.00      0.00       153\n",
      "\n",
      "avg / total       0.75      0.44      0.44      1212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\default.LAPTOP-2CI68M4P\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[777,   0,   0],\n",
       "       [368,   2,   0],\n",
       "       [153,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used RandomForestClassifier with reference to machine learning chart, explaination later\n",
    "rf = RandomForestClassifier(max_depth=3, n_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print('RandomForestClassifier : \\n' , classification_report(y_test, rf.predict(X_test)))\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3031 samples, validate on 1300 samples\n",
      "Epoch 1/10\n",
      " - 0s - loss: 8.2629 - acc: 0.3464 - val_loss: 6.4610 - val_acc: 0.5731\n",
      "Epoch 2/10\n",
      " - 0s - loss: 6.0540 - acc: 0.5539 - val_loss: 5.8103 - val_acc: 0.5646\n",
      "Epoch 3/10\n",
      " - 0s - loss: 4.7624 - acc: 0.3913 - val_loss: 2.8158 - val_acc: 0.5662\n",
      "Epoch 4/10\n",
      " - 0s - loss: 3.6391 - acc: 0.4952 - val_loss: 2.9377 - val_acc: 0.5177\n",
      "Epoch 5/10\n",
      " - 0s - loss: 2.7601 - acc: 0.4576 - val_loss: 2.1186 - val_acc: 0.4254\n",
      "Epoch 6/10\n",
      " - 0s - loss: 2.1706 - acc: 0.4306 - val_loss: 1.5329 - val_acc: 0.3123\n",
      "Epoch 7/10\n",
      " - 0s - loss: 1.5389 - acc: 0.4042 - val_loss: 2.4419 - val_acc: 0.5062\n",
      "Epoch 8/10\n",
      " - 0s - loss: 1.3039 - acc: 0.4289 - val_loss: 1.0831 - val_acc: 0.4446\n",
      "Epoch 9/10\n",
      " - 0s - loss: 1.0407 - acc: 0.4246 - val_loss: 1.0186 - val_acc: 0.4708\n",
      "Epoch 10/10\n",
      " - 0s - loss: 1.0123 - acc: 0.5609 - val_loss: 0.9999 - val_acc: 0.5708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23450de3a58>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use deep learning with reference to machine learning chart, explaination later\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7, input_dim=7, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "keras_model = build_model()\n",
    "keras_model.fit(x=X, y=y, batch_size=20, \n",
    "                epochs=10, verbose=2, callbacks=None, \n",
    "                validation_split=0.3, validation_data=None, \n",
    "                shuffle=True, class_weight=None, sample_weight=None, \n",
    "                initial_epoch= 0, steps_per_epoch=None, \n",
    "                validation_steps=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>time</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>models</th>\n",
       "      <th>params</th>\n",
       "      <th>queuelen</th>\n",
       "      <th>trials</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.568056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>11252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.715972</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.222917</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.424306</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4023.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type      time  dayofweek  models   params  queuelen  trials  duration\n",
       "0  13.0  0.568056        2.0   148.0  11252.0       0.0    40.0       2.0\n",
       "1  12.0  0.715972        2.0     7.0   5923.0       0.0    40.0       1.0\n",
       "2  13.0  0.222917        5.0    62.0   1906.0       1.0    20.0       0.0\n",
       "3   5.0  0.424306        5.0     8.0   4023.0      30.0    40.0       0.0\n",
       "4  12.0  0.672222        5.0     1.0   2480.0       0.0    40.0       1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_ml.csv')\n",
    "df.drop(columns='Unnamed: 0' , axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4331 entries, 0 to 4330\n",
      "Data columns (total 8 columns):\n",
      "type         3905 non-null float64\n",
      "time         4331 non-null float64\n",
      "dayofweek    4331 non-null float64\n",
      "models       4331 non-null float64\n",
      "params       3989 non-null float64\n",
      "queuelen     4331 non-null float64\n",
      "trials       4331 non-null float64\n",
      "duration     4331 non-null float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 270.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type         426\n",
       "time           0\n",
       "dayofweek      0\n",
       "models         0\n",
       "params       342\n",
       "queuelen       0\n",
       "trials         0\n",
       "duration       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 12.0,\n",
       " 13.0,\n",
       " nan,\n",
       " 14.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df.type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 5.0,\n",
       " 6.0,\n",
       " 7.0,\n",
       " 8.0,\n",
       " 9.0,\n",
       " 10.0,\n",
       " 11.0,\n",
       " 12.0,\n",
       " 13.0,\n",
       " 14.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dealng the Null in column \"type\": \n",
    "# |`type`|types of model categories, labels removed|\n",
    "# It is a categorical data. \n",
    "# So I don't think taking the mean or any mathematical methods makes sense. \n",
    "# Decided to Replace Null values with SOMETHING, new type number 1.\n",
    "# Since type 1 is missing.\n",
    "df.type.replace(np.nan, float(1), regex=True, inplace=True)         \n",
    "sorted(df.type.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>models</th>\n",
       "      <th>params</th>\n",
       "      <th>queuelen</th>\n",
       "      <th>trials</th>\n",
       "      <th>duration</th>\n",
       "      <th>type_1.0</th>\n",
       "      <th>type_2.0</th>\n",
       "      <th>type_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>type_5.0</th>\n",
       "      <th>type_6.0</th>\n",
       "      <th>type_7.0</th>\n",
       "      <th>type_8.0</th>\n",
       "      <th>type_9.0</th>\n",
       "      <th>type_10.0</th>\n",
       "      <th>type_11.0</th>\n",
       "      <th>type_12.0</th>\n",
       "      <th>type_13.0</th>\n",
       "      <th>type_14.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.568056</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>11252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715972</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222917</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.424306</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4023.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.672222</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  dayofweek  models   params  queuelen  trials  duration  type_1.0  \\\n",
       "0  0.568056        2.0   148.0  11252.0       0.0    40.0       2.0         0   \n",
       "1  0.715972        2.0     7.0   5923.0       0.0    40.0       1.0         0   \n",
       "2  0.222917        5.0    62.0   1906.0       1.0    20.0       0.0         0   \n",
       "3  0.424306        5.0     8.0   4023.0      30.0    40.0       0.0         0   \n",
       "4  0.672222        5.0     1.0   2480.0       0.0    40.0       1.0         0   \n",
       "\n",
       "   type_2.0  type_3.0    ...      type_5.0  type_6.0  type_7.0  type_8.0  \\\n",
       "0         0         0    ...             0         0         0         0   \n",
       "1         0         0    ...             0         0         0         0   \n",
       "2         0         0    ...             0         0         0         0   \n",
       "3         0         0    ...             1         0         0         0   \n",
       "4         0         0    ...             0         0         0         0   \n",
       "\n",
       "   type_9.0  type_10.0  type_11.0  type_12.0  type_13.0  type_14.0  \n",
       "0         0          0          0          0          1          0  \n",
       "1         0          0          0          1          0          0  \n",
       "2         0          0          0          0          1          0  \n",
       "3         0          0          0          0          0          0  \n",
       "4         0          0          0          1          0          0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy the \"type\" so model won't confused it with numerical, and took it as well correlated, which is not good.\n",
    "df_cat_dummy = pd.get_dummies(df['type'], prefix='type', drop_first=True)         #   Dummies all cats\n",
    "df = pd.concat([df.drop('type', axis=1) , df_cat_dummy],  axis=1)   # Merge back togather numeric with cats\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      3989.000000\n",
       "mean      10901.674354\n",
       "std       26059.953210\n",
       "min          71.000000\n",
       "25%         952.000000\n",
       "50%        2995.000000\n",
       "75%        6940.000000\n",
       "max      396701.000000\n",
       "Name: params, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dealng the Null in column \"param\": \n",
    "# |`params`|number of parameters to run in script|\n",
    "df.params.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23441016a58>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23440b4e278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['params'].plot(kind='box', stacked=True, figsize=(15,7))\n",
    "# Wah... this params skewed like hell.\n",
    "# Too many outlier, if remove might affect the distribution greatly. I think just leave it alone.\n",
    "# I will do scaling anyway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Null cells with mean, since it does not affect the original distribution much.\n",
    "df['params'].fillna(df['params'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time         0\n",
       "dayofweek    0\n",
       "models       0\n",
       "params       0\n",
       "queuelen     0\n",
       "trials       0\n",
       "duration     0\n",
       "type_1.0     0\n",
       "type_2.0     0\n",
       "type_3.0     0\n",
       "type_4.0     0\n",
       "type_5.0     0\n",
       "type_6.0     0\n",
       "type_7.0     0\n",
       "type_8.0     0\n",
       "type_9.0     0\n",
       "type_10.0    0\n",
       "type_11.0    0\n",
       "type_12.0    0\n",
       "type_13.0    0\n",
       "type_14.0    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23440fa3cc0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23440b602b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['params'].plot(kind='box', stacked=True, figsize=(15,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 5. 3. 1. 4. 7. 6.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>models</th>\n",
       "      <th>params</th>\n",
       "      <th>queuelen</th>\n",
       "      <th>trials</th>\n",
       "      <th>duration</th>\n",
       "      <th>type_1.0</th>\n",
       "      <th>type_2.0</th>\n",
       "      <th>type_3.0</th>\n",
       "      <th>type_4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>type_11.0</th>\n",
       "      <th>type_12.0</th>\n",
       "      <th>type_13.0</th>\n",
       "      <th>type_14.0</th>\n",
       "      <th>day_2.0</th>\n",
       "      <th>day_3.0</th>\n",
       "      <th>day_4.0</th>\n",
       "      <th>day_5.0</th>\n",
       "      <th>day_6.0</th>\n",
       "      <th>day_7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.568056</td>\n",
       "      <td>148.0</td>\n",
       "      <td>11252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.715972</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.222917</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.424306</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4023.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.672222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  models   params  queuelen  trials  duration  type_1.0  type_2.0  \\\n",
       "0  0.568056   148.0  11252.0       0.0    40.0       2.0         0         0   \n",
       "1  0.715972     7.0   5923.0       0.0    40.0       1.0         0         0   \n",
       "2  0.222917    62.0   1906.0       1.0    20.0       0.0         0         0   \n",
       "3  0.424306     8.0   4023.0      30.0    40.0       0.0         0         0   \n",
       "4  0.672222     1.0   2480.0       0.0    40.0       1.0         0         0   \n",
       "\n",
       "   type_3.0  type_4.0   ...     type_11.0  type_12.0  type_13.0  type_14.0  \\\n",
       "0         0         0   ...             0          0          1          0   \n",
       "1         0         0   ...             0          1          0          0   \n",
       "2         0         0   ...             0          0          1          0   \n",
       "3         0         0   ...             0          0          0          0   \n",
       "4         0         0   ...             0          1          0          0   \n",
       "\n",
       "   day_2.0  day_3.0  day_4.0  day_5.0  day_6.0  day_7.0  \n",
       "0        1        0        0        0        0        0  \n",
       "1        1        0        0        0        0        0  \n",
       "2        0        0        0        1        0        0  \n",
       "3        0        0        0        1        0        0  \n",
       "4        0        0        0        1        0        0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |`dayofweek`| day of week, 1 = monday, 7 = sunday |\n",
    "# This is categorical data too.\n",
    "print(df.dayofweek.unique())  # As suggested only 7 days.\n",
    "df_cat_dummy = pd.get_dummies(df['dayofweek'], prefix='day', drop_first=True)         #   Dummies all cats\n",
    "df = pd.concat([df.drop('dayofweek', axis=1) , df_cat_dummy],  axis=1)   # Merge back togather numeric with cats\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>models</th>\n",
       "      <th>params</th>\n",
       "      <th>queuelen</th>\n",
       "      <th>trials</th>\n",
       "      <th>duration</th>\n",
       "      <th>type_1.0</th>\n",
       "      <th>type_2.0</th>\n",
       "      <th>type_3.0</th>\n",
       "      <th>type_4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>type_11.0</th>\n",
       "      <th>type_12.0</th>\n",
       "      <th>type_13.0</th>\n",
       "      <th>type_14.0</th>\n",
       "      <th>day_2.0</th>\n",
       "      <th>day_3.0</th>\n",
       "      <th>day_4.0</th>\n",
       "      <th>day_5.0</th>\n",
       "      <th>day_6.0</th>\n",
       "      <th>day_7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "      <td>4331.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.572203</td>\n",
       "      <td>71.756638</td>\n",
       "      <td>10901.674354</td>\n",
       "      <td>53.383514</td>\n",
       "      <td>58.479104</td>\n",
       "      <td>0.728007</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.033941</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.021011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049642</td>\n",
       "      <td>0.093281</td>\n",
       "      <td>0.110367</td>\n",
       "      <td>0.120065</td>\n",
       "      <td>0.207573</td>\n",
       "      <td>0.208266</td>\n",
       "      <td>0.166705</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>0.037174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.165923</td>\n",
       "      <td>1701.084200</td>\n",
       "      <td>25009.629514</td>\n",
       "      <td>355.957245</td>\n",
       "      <td>68.839108</td>\n",
       "      <td>0.891271</td>\n",
       "      <td>0.297836</td>\n",
       "      <td>0.181099</td>\n",
       "      <td>0.178099</td>\n",
       "      <td>0.143438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217230</td>\n",
       "      <td>0.290859</td>\n",
       "      <td>0.313383</td>\n",
       "      <td>0.325075</td>\n",
       "      <td>0.405616</td>\n",
       "      <td>0.406115</td>\n",
       "      <td>0.372755</td>\n",
       "      <td>0.409555</td>\n",
       "      <td>0.085649</td>\n",
       "      <td>0.189209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.454167</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1029.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.584722</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>3240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.691667</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>10636.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.999306</td>\n",
       "      <td>87293.000000</td>\n",
       "      <td>396701.000000</td>\n",
       "      <td>5605.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              time        models         params     queuelen       trials  \\\n",
       "count  4331.000000   4331.000000    4331.000000  4331.000000  4331.000000   \n",
       "mean      0.572203     71.756638   10901.674354    53.383514    58.479104   \n",
       "std       0.165923   1701.084200   25009.629514   355.957245    68.839108   \n",
       "min       0.000694      1.000000      71.000000     0.000000     5.000000   \n",
       "25%       0.454167      5.000000    1029.500000     0.000000    40.000000   \n",
       "50%       0.584722     13.000000    3240.000000     0.000000    40.000000   \n",
       "75%       0.691667     26.000000   10636.000000     0.000000    40.000000   \n",
       "max       0.999306  87293.000000  396701.000000  5605.000000   400.000000   \n",
       "\n",
       "          duration     type_1.0     type_2.0     type_3.0     type_4.0  \\\n",
       "count  4331.000000  4331.000000  4331.000000  4331.000000  4331.000000   \n",
       "mean      0.728007     0.098361     0.033941     0.032787     0.021011   \n",
       "std       0.891271     0.297836     0.181099     0.178099     0.143438   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       3.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          ...         type_11.0    type_12.0    type_13.0    type_14.0  \\\n",
       "count     ...       4331.000000  4331.000000  4331.000000  4331.000000   \n",
       "mean      ...          0.049642     0.093281     0.110367     0.120065   \n",
       "std       ...          0.217230     0.290859     0.313383     0.325075   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "max       ...          1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           day_2.0      day_3.0      day_4.0      day_5.0      day_6.0  \\\n",
       "count  4331.000000  4331.000000  4331.000000  4331.000000  4331.000000   \n",
       "mean      0.207573     0.208266     0.166705     0.213115     0.007389   \n",
       "std       0.405616     0.406115     0.372755     0.409555     0.085649   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           day_7.0  \n",
       "count  4331.000000  \n",
       "mean      0.037174  \n",
       "std       0.189209  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing X and y\n",
    "X = df.drop(\"duration\", axis=1).values\n",
    "mms = MinMaxScaler()\n",
    "X = mms.fit_transform(X)\n",
    "\n",
    "y = df['duration'].values\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "\n",
    "# train_test_split 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.89      0.88       662\n",
      "          1       0.75      0.63      0.68       405\n",
      "          2       0.81      0.45      0.58       144\n",
      "\n",
      "avg / total       0.82      0.75      0.78      1211\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[689,  57,   5],\n",
       "       [139, 256,  10],\n",
       "       [ 49,  30,  65]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=20, n_estimators=30)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print('RandomForestClassifier : \\n' , classification_report(y_test, rf.predict(X_test)))\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine turning - GridSearch with cv=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\default.LAPTOP-2CI68M4P\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\default.LAPTOP-2CI68M4P\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [2200], 'max_depth': [870], 'max_features': [20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier() \n",
    "\n",
    "# The version below is already fine tuned, just in case you re-run this again to cut short run-time.\n",
    "param_grid = { \n",
    "    'n_estimators': [2200],\n",
    "    'max_depth' : [870],\n",
    "    'max_features': [20]\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(n_jobs=-1, estimator=rfc, param_grid=param_grid, cv= 10)\n",
    "CV_rfc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric -  classification_report / Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 870, 'max_features': 20, 'n_estimators': 2200}\n",
      "RandomForestClassifier : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.89      0.89       662\n",
      "          1       0.75      0.70      0.72       405\n",
      "          2       0.69      0.50      0.58       144\n",
      "\n",
      "avg / total       0.82      0.78      0.80      1211\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[678,  57,  16],\n",
       "       [105, 283,  17],\n",
       "       [ 33,  39,  72]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(CV_rfc.best_params_) # out[] : {'max_depth': 870, 'max_features': 'auto', 'n_estimators': 2200}\n",
    "print('RandomForestClassifier : \\n' , classification_report(y_test, CV_rfc.predict(X_test)))\n",
    "y_pred = CV_rfc.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning\n",
    "Just giving this method a shot. I have done a few different models, this one gets the best val_acc. Well, not as good as randomforest, so you may ignore the result here. Things that I have tried (I did not display here to avoid confusion), tried for example adding many layers, use batchnormaliztion, change activation to sigmoid instead of relu, optimaizer used adam instead of SGD. etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4331, 25)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3031 samples, validate on 1300 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.0170 - acc: 0.4226 - val_loss: 0.9969 - val_acc: 0.5085\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.9894 - acc: 0.5081 - val_loss: 0.9725 - val_acc: 0.5238\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.9683 - acc: 0.5328 - val_loss: 0.9534 - val_acc: 0.5623\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.9519 - acc: 0.5592 - val_loss: 0.9388 - val_acc: 0.5615\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.9392 - acc: 0.5599 - val_loss: 0.9270 - val_acc: 0.5646\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.9289 - acc: 0.5645 - val_loss: 0.9174 - val_acc: 0.5677\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.9204 - acc: 0.5668 - val_loss: 0.9095 - val_acc: 0.5677\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.9133 - acc: 0.5665 - val_loss: 0.9030 - val_acc: 0.5685\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.9074 - acc: 0.5681 - val_loss: 0.8975 - val_acc: 0.5700\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.9024 - acc: 0.5688 - val_loss: 0.8928 - val_acc: 0.5715\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.8980 - acc: 0.5694 - val_loss: 0.8886 - val_acc: 0.5731\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.8941 - acc: 0.5701 - val_loss: 0.8848 - val_acc: 0.5731\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.8905 - acc: 0.5701 - val_loss: 0.8813 - val_acc: 0.5738\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.8871 - acc: 0.5704 - val_loss: 0.8779 - val_acc: 0.5738\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.8838 - acc: 0.5704 - val_loss: 0.8748 - val_acc: 0.5738\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.8806 - acc: 0.5704 - val_loss: 0.8716 - val_acc: 0.5738\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.8773 - acc: 0.5734 - val_loss: 0.8685 - val_acc: 0.5877\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.8741 - acc: 0.5863 - val_loss: 0.8656 - val_acc: 0.5954\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.8709 - acc: 0.5912 - val_loss: 0.8625 - val_acc: 0.6000\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.8677 - acc: 0.5998 - val_loss: 0.8593 - val_acc: 0.6046\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.8643 - acc: 0.6008 - val_loss: 0.8561 - val_acc: 0.6046\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.8610 - acc: 0.6011 - val_loss: 0.8530 - val_acc: 0.6046\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.8576 - acc: 0.6024 - val_loss: 0.8498 - val_acc: 0.6146\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.8543 - acc: 0.6123 - val_loss: 0.8466 - val_acc: 0.6215\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.8509 - acc: 0.6176 - val_loss: 0.8434 - val_acc: 0.6200\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.8474 - acc: 0.6236 - val_loss: 0.8401 - val_acc: 0.6362\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.8439 - acc: 0.6368 - val_loss: 0.8369 - val_acc: 0.6362\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.8405 - acc: 0.6371 - val_loss: 0.8336 - val_acc: 0.6362\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.8369 - acc: 0.6354 - val_loss: 0.8303 - val_acc: 0.6300\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.8333 - acc: 0.6331 - val_loss: 0.8271 - val_acc: 0.6308\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.8298 - acc: 0.6404 - val_loss: 0.8239 - val_acc: 0.6392\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.8263 - acc: 0.6437 - val_loss: 0.8206 - val_acc: 0.6400\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.8228 - acc: 0.6434 - val_loss: 0.8174 - val_acc: 0.6400\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.8193 - acc: 0.6440 - val_loss: 0.8144 - val_acc: 0.6408\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.8159 - acc: 0.6440 - val_loss: 0.8112 - val_acc: 0.6431\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.8123 - acc: 0.6424 - val_loss: 0.8078 - val_acc: 0.6423\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.8083 - acc: 0.6410 - val_loss: 0.8042 - val_acc: 0.6438\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.8042 - acc: 0.6417 - val_loss: 0.8003 - val_acc: 0.6423\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.7999 - acc: 0.6453 - val_loss: 0.7964 - val_acc: 0.6431\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.7956 - acc: 0.6457 - val_loss: 0.7927 - val_acc: 0.6423\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.7915 - acc: 0.6457 - val_loss: 0.7892 - val_acc: 0.6423\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.7876 - acc: 0.6453 - val_loss: 0.7858 - val_acc: 0.6431\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.7838 - acc: 0.6447 - val_loss: 0.7827 - val_acc: 0.6431\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.7802 - acc: 0.6450 - val_loss: 0.7796 - val_acc: 0.6423\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.7767 - acc: 0.6443 - val_loss: 0.7766 - val_acc: 0.6431\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.7733 - acc: 0.6453 - val_loss: 0.7738 - val_acc: 0.6423\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.7702 - acc: 0.6467 - val_loss: 0.7709 - val_acc: 0.6454\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.7671 - acc: 0.6473 - val_loss: 0.7683 - val_acc: 0.6446\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.7640 - acc: 0.6490 - val_loss: 0.7659 - val_acc: 0.6469\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.7612 - acc: 0.6516 - val_loss: 0.7635 - val_acc: 0.6492\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.7584 - acc: 0.6516 - val_loss: 0.7613 - val_acc: 0.6485\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.7558 - acc: 0.6516 - val_loss: 0.7593 - val_acc: 0.6477\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.7534 - acc: 0.6519 - val_loss: 0.7574 - val_acc: 0.6477\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.7511 - acc: 0.6523 - val_loss: 0.7556 - val_acc: 0.6477\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.7489 - acc: 0.6523 - val_loss: 0.7540 - val_acc: 0.6485\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.7469 - acc: 0.6519 - val_loss: 0.7524 - val_acc: 0.6485\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.7449 - acc: 0.6519 - val_loss: 0.7510 - val_acc: 0.6485\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.7430 - acc: 0.6526 - val_loss: 0.7496 - val_acc: 0.6500\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.7412 - acc: 0.6539 - val_loss: 0.7483 - val_acc: 0.6485\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.7396 - acc: 0.6542 - val_loss: 0.7470 - val_acc: 0.6500\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.7380 - acc: 0.6539 - val_loss: 0.7459 - val_acc: 0.6500\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.7363 - acc: 0.6536 - val_loss: 0.7448 - val_acc: 0.6500\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.7350 - acc: 0.6542 - val_loss: 0.7438 - val_acc: 0.6492\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.7336 - acc: 0.6532 - val_loss: 0.7428 - val_acc: 0.6492\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.7322 - acc: 0.6536 - val_loss: 0.7419 - val_acc: 0.6492\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.7309 - acc: 0.6536 - val_loss: 0.7411 - val_acc: 0.6492\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.7298 - acc: 0.6536 - val_loss: 0.7402 - val_acc: 0.6492\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.7286 - acc: 0.6542 - val_loss: 0.7394 - val_acc: 0.6508\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.7272 - acc: 0.6542 - val_loss: 0.7388 - val_acc: 0.6523\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.7264 - acc: 0.6552 - val_loss: 0.7380 - val_acc: 0.6523\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.7254 - acc: 0.6552 - val_loss: 0.7375 - val_acc: 0.6531\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.7245 - acc: 0.6579 - val_loss: 0.7366 - val_acc: 0.6531\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.7234 - acc: 0.6569 - val_loss: 0.7360 - val_acc: 0.6531\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.7226 - acc: 0.6585 - val_loss: 0.7353 - val_acc: 0.6531\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.7216 - acc: 0.6579 - val_loss: 0.7346 - val_acc: 0.6531\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.7208 - acc: 0.6585 - val_loss: 0.7341 - val_acc: 0.6531\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.7200 - acc: 0.6585 - val_loss: 0.7335 - val_acc: 0.6531\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.7191 - acc: 0.6595 - val_loss: 0.7329 - val_acc: 0.6531\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.7184 - acc: 0.6579 - val_loss: 0.7324 - val_acc: 0.6531\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.7177 - acc: 0.6595 - val_loss: 0.7319 - val_acc: 0.6546\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.7170 - acc: 0.6598 - val_loss: 0.7313 - val_acc: 0.6546\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.7163 - acc: 0.6595 - val_loss: 0.7308 - val_acc: 0.6546\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.7157 - acc: 0.6592 - val_loss: 0.7303 - val_acc: 0.6546\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.7151 - acc: 0.6598 - val_loss: 0.7298 - val_acc: 0.6546\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.7144 - acc: 0.6598 - val_loss: 0.7294 - val_acc: 0.6554\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.7138 - acc: 0.6605 - val_loss: 0.7289 - val_acc: 0.6562\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.7133 - acc: 0.6618 - val_loss: 0.7284 - val_acc: 0.6562\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.7127 - acc: 0.6618 - val_loss: 0.7280 - val_acc: 0.6577\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.7121 - acc: 0.6618 - val_loss: 0.7275 - val_acc: 0.6577\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.7116 - acc: 0.6622 - val_loss: 0.7274 - val_acc: 0.6585\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.7111 - acc: 0.6625 - val_loss: 0.7270 - val_acc: 0.6592\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.7105 - acc: 0.6625 - val_loss: 0.7264 - val_acc: 0.6577\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.7100 - acc: 0.6635 - val_loss: 0.7260 - val_acc: 0.6577\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.7095 - acc: 0.6638 - val_loss: 0.7255 - val_acc: 0.6577\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.7090 - acc: 0.6638 - val_loss: 0.7251 - val_acc: 0.6577\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.7085 - acc: 0.6635 - val_loss: 0.7246 - val_acc: 0.6585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 0s - loss: 0.7080 - acc: 0.6645 - val_loss: 0.7242 - val_acc: 0.6592\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.7075 - acc: 0.6655 - val_loss: 0.7240 - val_acc: 0.6608\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.7072 - acc: 0.6661 - val_loss: 0.7234 - val_acc: 0.6600\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.7067 - acc: 0.6661 - val_loss: 0.7231 - val_acc: 0.6600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2344b8786d8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deep learning\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=25, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(lr=0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "keras_model = build_model()\n",
    "keras_model.fit(x=X, y=y, batch_size=10, \n",
    "                epochs=100, verbose=2, callbacks=None, \n",
    "                validation_split=0.3, validation_data=None, \n",
    "                shuffle=True, class_weight=None, sample_weight=None, \n",
    "                initial_epoch= 0, steps_per_epoch=None, \n",
    "                validation_steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal:\n",
    "Target y is to predict duration. In this case, its a classification problem, as duration is classed, [0,1,2]. \n",
    "Feature X, will be the rest of the columns.\n",
    "\n",
    "##### Baseline:\n",
    "Without doing any feature selection, its good to find out the baseline accuracy first, so that we know if there is any improvement from our model. <br>\n",
    "Random Forest F1 score 0.44 <br>\n",
    "Deep learning val_loss: 0.9999 - val_acc: 0.5708\n",
    "\n",
    "##### Model selection:\n",
    "Refering to the 2 charts below. Our data is only 4000 plus, supervised learning. So we need a multiclassifier. Ensemble decision tree (aka randomforest) or a neural network will be good enough. If there is more time, perhaps I will add in ensemble SVM, gradient boosting tree.\n",
    "\n",
    "<img src='ml_chart1.png' width=\"800px\"> \n",
    "<img src='ml_chart2.png' width=\"800px\">\n",
    "\n",
    "##### EDA\n",
    "- Dataset is not big. Only 8 features, and 4000 plus rows. \n",
    "- We had to deal with Null values found in Type and Param.\n",
    "- Type is types of model categories, It is a categorical data. 10% are null. So I don't think taking the mean or any mathematical methods makes sense. Therefore decided to replace Null values with a new type number 1, since type#1 is missing. <br>\n",
    "- Param is number of parameters to run in script, numerical data. 8% are null. The distribtion shewed with many outliers. Decided to replace null value with mean, since it does not affect the distribution. \n",
    "- dayofweek and type are categorical. And they are in accending order. Fitting such data into model will confuse the model for correlation, this is bad. Therefore get dummies is neccessary.\n",
    "- Checking the rest of the distribution, almost all features are shewed and have many outliers. Removing outliers will alter the distribution and reduce size of the already small dataset. Therefore decided leave outliers alone and do MinMax scaling all X.\n",
    "\n",
    "##### Feature selections cum Fine tuning\n",
    "Even after dummy the categorical features, the dataset is not wide enough to be a concern. Therefore, decided to do feature selection and fine tuning together at one go through Gridsearch randonforest. <br>\n",
    "Best result so far: <br>\n",
    "Overall precision=0.82, recall=0.78, F1-score 0.80. This is a significant improvement from baseline. <br>\n",
    "Whereas the deep learning NN method doesn't show much improvement even after adding more nodes or layers. Best val_acc 0.66. Some improvement from baseline, but not significant improvement.\n",
    "\n",
    "#### Conclusion:\n",
    "Randomforest is the winner over deep learning. Given more time, I will try other models such as ensemble SVM and gradient boosting tree, as the chart suggest that this are the other suitable model for a small dataset and for accuracy reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "<img src='aisg_logo.png' width=\"700px\">  \n",
    "<br>\n",
    "# AI Apprentice Programme\n",
    "## Take-home Written Assignment\n",
    "\n",
    "### Problem 3 - Mathematics: Calculus and Linear Algebra\n",
    "Problems revolving around AI and machine learning are, at its core, mathematical problems. A team looking to solve these problems must be equiped with strong quantitative capabilities.\n",
    "\n",
    "This problem will test your fundamental mathematical knowledge in the area of machine learning. __You are not allowed to use any pre-built algorithms for this challenge, unless otherwise stated__.\n",
    "\n",
    "You will be assessed on 1) your method of solving the problems, and 2) the correctness of your solution.\n",
    "\n",
    "You should be able to complete this question in 60 minutes for these problems. However, you are not limited to this time frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "You are a machine learning engineer in the medieval times, where computers and sklearn do not exist. Your boss wants you to build a linear regressor to predict housing prices. He has 3 huts, which he wants you to conduct the problem on. The goal of this model is to predict the price, `p` in terms of the number of bedrooms `b` and toilets `t`.\n",
    "\n",
    "| num_bedrooms, `b` | num_toilets, `t` | price(grams of gold), `p` |\n",
    "|-|-|-|\n",
    "|3|1|30|\n",
    "|6|1|55|\n",
    "|3|3|70|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Gradient Descent\n",
    "For this question, no computing aids are allowed. You may choose to scan a copy of your worked solution, or write it in text or LaTeX within the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Derive the hypothesis for a linear regression model based on $\\theta$s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Derive the full (mean-squared error) MSE cost function of this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Derive the gradient w.r.t. each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Using a learning rate, $\\alpha = 1$, and initializing $\\theta$ at [0, 0, 0], determine the new $\\theta$ after one round of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Being computational in nature, this approach requires many steps, which is not human-friendly in nature. Using a more analytical approach, provide the optimal weights for $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. How can we verify that this answer is correct? Please show your working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Regularization\n",
    "\n",
    "For this question, we would value answers that display both a strong theoretical understanding of the topic of regularisation, as well as the the ability to apply this theoretical understanding to practical problems.\n",
    "\n",
    "Where possible, you are also encouraged to use numerical examples as elaboration on theoretical concepts you introduce. In other words, blindly copying from Wikipedia or Stack Exchange is not encouraged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. In your own words of a few sentences, explain what regularisation means. Specifically, what is the problem that occurs naturally in unregularised cost functions, and how does regularisation fix it? Also, given a regularisation parameter $\\lambda$, what is $\\lambda$ trying to account for? How does a $\\lambda$ slightly greater than the optimal value affect, and how does a slightly smaller $\\lambda$ affect it? How does $\\lambda = 0$ and $\\lambda = \\infty$ affect it? How does regularisation affect the mathematical complexity and search space of the problem? (By complexity, we mean that a higher order polynomial would increase the complexity.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Explain the differences in a few sentences between L1 and L2 regularisation. Specifically, which one is capable of eliminating coefficients, and why is it able to do so, while the other is unable to do so? In addition, are these regularisation methods differentiable, and if not, how do we implement gradient descent for it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
